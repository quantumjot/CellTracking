{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAPARI visualization of UNet Training Data\n",
    "\n",
    "You can use this notebook to view, modified and save out training data for UNet models\n",
    "\n",
    "Labels:\n",
    "+ 0 - background \n",
    "+ 1 - GFP/Phase \n",
    "+ 2 - RFP\n",
    "\n",
    "\n",
    "Extra key bindings:\n",
    "+ 'w' - calculate weightmap\n",
    "+ 's' - save labels\n",
    "+ 'o' - output all weightmaps and metadata for tfrecord creation\n",
    "+ '\\>' - grow the label under the mouse cursor\n",
    "+ '\\<' - shrink the label under the mouse cursor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "```\n",
    "Authors:\n",
    "- Alan R. Lowe (a.lowe@ucl.ac.uk)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Set up the data path and channel used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH = '/Users/arl/Dropbox/Data/TrainingData/UNet_training_Scribble'\n",
    "DATA_PATH = '/home/arl/Dropbox/Data/Nathan/UNet_training_SHARC_v3'\n",
    "WEIGHT_AMPLITUDE = 30.\n",
    "ACQUISION_CHANNELS = ['PHASE']\n",
    "# ACQUISION_CHANNELS = ['GFP', 'RFP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import enum\n",
    "import json\n",
    "import napari\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "from scipy.ndimage.morphology import distance_transform_edt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@enum.unique\n",
    "class Channels(enum.Enum):\n",
    "    BRIGHTFIELD = 0 \n",
    "    GFP = 1\n",
    "    RFP = 2\n",
    "    IRFP = 3\n",
    "    PHASE = 4\n",
    "    WEIGHTS = 98\n",
    "    MASK = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_modified_filename(filename):\n",
    "    if filename.endswith('.modified.tif'):\n",
    "        stripped_fn = filename[:-len('.modified.tif')]\n",
    "        return stripped_fn\n",
    "    return filename\n",
    "\n",
    "def make_folder(foldername):\n",
    "    if os.path.exists(foldername):\n",
    "        return\n",
    "    os.mkdir(foldername)\n",
    "    \n",
    "def file_root(filename):\n",
    "    FILENAME_PATTERN = r'([a-zA-Z0-9]+)_([a-zA-Z0-9]+)_*.tif'\n",
    "    grps = re.search(FILENAME_PATTERN, filename)\n",
    "    return grps\n",
    "\n",
    "def load_training_data(pth, channels=[Channels.GFP, Channels.RFP]):\n",
    "    \"\"\" load training data for visualisation with napari \"\"\"\n",
    "    \n",
    "   \n",
    "    \n",
    "    # find the sets and sort them\n",
    "    sets = [f for f in os.listdir(pth) if os.path.isdir(os.path.join(pth, f))]\n",
    "    sets.sort(key = lambda s: int(s[3:]))\n",
    "    \n",
    "    def set_filename_format(filename):\n",
    "        grps = file_root(filename)\n",
    "        if grps.group(1) in [c.name.lower() for c in all_channels]:\n",
    "            FILENAME_FORMAT = 2\n",
    "        else:\n",
    "            FILENAME_FORMAT = 1\n",
    "            \n",
    "        def filename_formatter(filename, channel):\n",
    "            # assert(channel in [c.name.lower() for c in all_channels])\n",
    "            grps = file_root(filename)\n",
    "\n",
    "            return f'{grps.group(FILENAME_FORMAT)}_{channel}.tif'\n",
    "            # return '{}_{}.tif'.format(*[channel, grps.group(FILENAME_FORMAT)])\n",
    "        \n",
    "        return filename_formatter\n",
    "    \n",
    "    all_channels = [Channels.MASK, Channels.WEIGHTS]+channels\n",
    "    files = {k:{'files':[], 'data':[], 'sets':[], 'path':[]} for k in all_channels}\n",
    "    all_channels.remove(Channels.WEIGHTS)\n",
    "    \n",
    "    for s in sets:\n",
    "\n",
    "        # root_folders\n",
    "        l_root = os.path.join(pth, s, 'labels')\n",
    "        \n",
    "        # check that this folder exists \n",
    "        if not os.path.exists(l_root):\n",
    "            raise IOError(f'{l_root} does not exist. Do you need to rename label -> labels?')\n",
    "\n",
    "        # get the training label files\n",
    "        label_files = [f for f in os.listdir(l_root) if f.endswith('.tif')]\n",
    "        \n",
    "        # sort to remove unmodified files and replace with the modified files\n",
    "        unmodified_files, modified_files = [], []\n",
    "        for i, f in enumerate(label_files):\n",
    "            if f.endswith('.modified.tif'):\n",
    "                modified_files.append(strip_modified_filename(f))\n",
    "            else:\n",
    "                unmodified_files.append(f)\n",
    "                \n",
    "        unmodified_files = list(set(unmodified_files).difference(set(modified_files)))\n",
    "        label_files = unmodified_files + [f+'.modified.tif' for f in modified_files]\n",
    "        \n",
    "#         print(label_files)\n",
    "        fnfmt = set_filename_format(label_files[0])\n",
    "                \n",
    "        files[Channels.MASK]['path'] += [s+'/labels/'+f for f in label_files]\n",
    "        files[Channels.MASK]['files'] += [strip_modified_filename(f) for f in label_files]\n",
    "        files[Channels.MASK]['data'] += [io.imread(os.path.join(l_root, f)) for f in label_files]\n",
    "        files[Channels.MASK]['sets'] += [s] * len(label_files)\n",
    "        \n",
    "        for channel in channels:\n",
    "            cfiles = [fnfmt(l, channel.name.lower()) for l in label_files]\n",
    "            files[channel]['path'] += [s+'/'+channel.name.lower()+'/'+f for f in cfiles]\n",
    "            files[channel]['files'] += cfiles\n",
    "            files[channel]['data'] += [io.imread(os.path.join(pth, s, channel.name.lower(), f)) for f in cfiles]\n",
    "            files[channel]['sets'] += [s] * len(label_files)\n",
    "            \n",
    "        # now look for weights \n",
    "        w_root = os.path.join(pth, s, 'weights')\n",
    "#         if os.path.exists(w_root):\n",
    "        wfiles = [fnfmt(l, 'weights') for l in label_files]\n",
    "        for weight_file in wfiles:\n",
    "            files[Channels.WEIGHTS]['path'] += [f'{s}/weights/{weight_file}']\n",
    "            files[Channels.WEIGHTS]['files'] += [weight_file]\n",
    "            files[Channels.WEIGHTS]['sets'] += [s]\n",
    "            if os.path.exists(os.path.join(w_root, weight_file)):\n",
    "                files[Channels.WEIGHTS]['data'] += [io.imread(os.path.join(w_root, weight_file)).astype(np.float32)]\n",
    "            else:\n",
    "                print(f'Adding empty weight file: {weight_file}')\n",
    "                mask_shape = files[channels[0]]['data'][0].shape\n",
    "                files[Channels.WEIGHTS]['data'] += [np.zeros(mask_shape, dtype=np.float32)]\n",
    "                                                         \n",
    "    # now make image stacks \n",
    "    for channel in files.keys():\n",
    "        \n",
    "        for i, im in enumerate(files[channel]['data']):\n",
    "            print(channel, files[channel]['path'][i], im.shape, im.dtype)\n",
    "        \n",
    "        files[channel]['data'] = np.stack(files[channel]['data'], axis=0)\n",
    "\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding empty weight file: 0100_weights.tif\n",
      "Channels.MASK set1/labels/0100_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set2/labels/0031_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set3/labels/0000_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set4/labels/0000_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set4/labels/0321_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set5/labels/0005_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set5/labels/0009_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set5/labels/0000_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set5/labels/0002_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set6/labels/0009_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set7/labels/0229_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set8/labels/0000_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set8/labels/0001_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set9/labels/0020_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set9/labels/0441_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set10/labels/0000_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set10/labels/0502_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set10/labels/1092_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set11/labels/0625_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set12/labels/0033_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set12/labels/0566_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set13/labels/0218_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set13/labels/0409_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set13/labels/0659_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set13/labels/0039_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set13/labels/0356_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set14/labels/0144_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set14/labels/0010_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set15/labels/1000_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set15/labels/0845_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set15/labels/0802_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set15/labels/0045_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set15/labels/0997_mask.tif (1024, 1024) uint8\n",
      "Channels.MASK set15/labels/1091_mask.tif (1024, 1024) uint8\n",
      "Channels.WEIGHTS set1/weights/0100_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set2/weights/0031_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set3/weights/0000_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set4/weights/0000_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set4/weights/0321_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set5/weights/0005_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set5/weights/0009_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set5/weights/0000_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set5/weights/0002_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set6/weights/0009_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set7/weights/0229_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set8/weights/0000_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set8/weights/0001_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set9/weights/0020_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set9/weights/0441_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set10/weights/0000_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set10/weights/0502_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set10/weights/1092_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set11/weights/0625_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set12/weights/0033_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set12/weights/0566_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set13/weights/0218_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set13/weights/0409_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set13/weights/0659_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set13/weights/0039_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set13/weights/0356_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set14/weights/0144_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set14/weights/0010_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set15/weights/1000_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set15/weights/0845_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set15/weights/0802_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set15/weights/0045_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set15/weights/0997_weights.tif (1024, 1024) float32\n",
      "Channels.WEIGHTS set15/weights/1091_weights.tif (1024, 1024) float32\n",
      "Channels.PHASE set1/phase/0100_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set2/phase/0031_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set3/phase/0000_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set4/phase/0000_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set4/phase/0321_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set5/phase/0005_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set5/phase/0009_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set5/phase/0000_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set5/phase/0002_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set6/phase/0009_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set7/phase/0229_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set8/phase/0000_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set8/phase/0001_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set9/phase/0020_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set9/phase/0441_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set10/phase/0000_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set10/phase/0502_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set10/phase/1092_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set11/phase/0625_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set12/phase/0033_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set12/phase/0566_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set13/phase/0218_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set13/phase/0409_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set13/phase/0659_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set13/phase/0039_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set13/phase/0356_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set14/phase/0144_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set14/phase/0010_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set15/phase/1000_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set15/phase/0845_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set15/phase/0802_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set15/phase/0045_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set15/phase/0997_phase.tif (1024, 1024) float32\n",
      "Channels.PHASE set15/phase/1091_phase.tif (1024, 1024) float32\n"
     ]
    }
   ],
   "source": [
    "channels = [Channels[c.upper()] for c in ACQUISION_CHANNELS]\n",
    "data = load_training_data(DATA_PATH, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(stack):\n",
    "    normed = stack.astype(np.float32)\n",
    "    for i in range(stack.shape[0]):\n",
    "        # normed[i,...] = (normed[i,...]-np.mean(normed[i,...])) / np.std(normed[i,...])\n",
    "        c = normed[i,...]\n",
    "        p_lo = np.percentile(c,5)\n",
    "        p_hi = np.percentile(c,99)\n",
    "        normed[i,...] = np.clip((c - p_lo) / p_hi, 0., 1.)\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_boxes(seg):\n",
    "    lbl, nlbl = ndimage.label(seg)\n",
    "    class_label, _, minxy, maxxy = ndimage.extrema(seg, lbl, index=np.arange(1, nlbl+1))\n",
    "    return class_label, minxy, maxxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = np.zeros(data[channels[0]]['data'].shape, dtype=np.uint8)\n",
    "mask = data[Channels.MASK]['data']\n",
    "if mask.ndim == 3:\n",
    "    seg = mask > 0\n",
    "elif mask.ndim == 4:\n",
    "    seg[mask[:,0,...]>0] = 1\n",
    "    seg[mask[:,1,...]>0] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_mask(labels, unique_labels=range(1,len(channels)+1)):\n",
    "    print(unique_labels)\n",
    "    seg = np.zeros((len(unique_labels),)+labels.shape, dtype=np.uint8)\n",
    "    for i,l in enumerate(unique_labels):\n",
    "        seg[i,...] = labels==l\n",
    "    return np.squeeze(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_labels(viewer):\n",
    "    # get the current image \n",
    "    current_slice = viewer.layers[viewer.active_layer].coordinates[0]\n",
    "    source_set = data[Channels.MASK]['sets'][current_slice]\n",
    "    source_file = data[Channels.MASK]['files'][current_slice]\n",
    "    source_fn = os.path.join(source_set, 'labels', source_file)\n",
    "\n",
    "    # get the current layer\n",
    "    current_labels = viewer.layers['labels'].data[current_slice,...]\n",
    "    current_mask = convert_to_mask(current_labels)\n",
    "\n",
    "    # write out the modified segmentation mask\n",
    "    new_file = os.path.join(DATA_PATH, source_fn+'.modified.tif')\n",
    "    print(new_file)\n",
    "    io.imsave(new_file, current_mask.astype('uint8'))\n",
    "\n",
    "    print(current_slice, current_labels.shape, new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weightmaps = np.zeros((seg.shape), dtype=np.float32)\n",
    "\n",
    "def calculate_weightmaps(viewer, w0=WEIGHT_AMPLITUDE, current_slice=0):\n",
    "    # get the current layer and make it binary\n",
    "    mask = viewer.layers['labels'].data[current_slice,...].astype(np.bool)\n",
    "    \n",
    "    # label the image \n",
    "    labelled, n_labels = ndimage.label(mask)\n",
    "    weight_mask = np.zeros(mask.shape, dtype=np.float32)\n",
    "    for i in range(1,n_labels+1):\n",
    "        cell = labelled == i\n",
    "        not_cell = np.logical_xor(cell, mask) #np.logical_and(labelled != i, labelled > 0)\n",
    "        mask_diff = gaussian_filter(cell.astype(np.float32), sigma=5) * gaussian_filter(not_cell.astype(np.float32), sigma=5)\n",
    "        weight_mask += mask_diff\n",
    "\n",
    "    wmap = w0*weight_mask #* wmap\n",
    "    \n",
    "    # normalize it\n",
    "    wmap += 1.   \n",
    "    wmap[mask] = 1.\n",
    "        \n",
    "    viewer.layers['weightmaps'].data[current_slice,...] = wmap.astype(np.float32)\n",
    "    viewer.layers['weightmaps'].contrast_limits = (np.min(wmap), np.max(wmap))\n",
    "    viewer.layers['weightmaps'].visible = True\n",
    "    \n",
    "    return wmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grow_shrink_label(viewer, grow=True, n_iter=1):\n",
    "    # get the current image \n",
    "    current_slice = viewer.layers[viewer.active_layer].coordinates[0]\n",
    "    current_labels = viewer.layers['labels'].data[current_slice,...]\n",
    "    \n",
    "    cursor_coords = [int(p) for p in viewer.layers[viewer.active_layer].position]\n",
    "    labelled, _ = ndimage.label(current_labels.astype(np.bool))\n",
    "    real_label = current_labels[cursor_coords[0], cursor_coords[1]]\n",
    "    \n",
    "    if real_label < 1: return\n",
    "    \n",
    "    mask = labelled == labelled[cursor_coords[0], cursor_coords[1]]\n",
    "    if grow:\n",
    "        mask = ndimage.morphology.binary_dilation(mask, iterations=n_iter)\n",
    "    else:\n",
    "        current_labels[mask] = 0\n",
    "        mask = ndimage.morphology.binary_erosion(mask, iterations=n_iter)\n",
    "    \n",
    "    current_labels[mask] = real_label\n",
    "    viewer.layers['labels'].data[current_slice,...] = current_labels\n",
    "    viewer.layers['labels']._set_view_slice()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output all with metadata\n",
      "Weighmap 0 is empty. Calculating...\n",
      "/home/arl/Dropbox/Data/Nathan/UNet_training_SHARC_v3/set1/weights 0100_weights.tif\n"
     ]
    }
   ],
   "source": [
    "# start napari\n",
    "with napari.gui_qt():\n",
    "    viewer = napari.Viewer()\n",
    "    \n",
    "    if Channels.GFP in data:\n",
    "        gfp = normalize_images(data[Channels.GFP]['data'])\n",
    "        viewer.add_image(gfp, name='GFP', colormap='green', contrast_limits=(0.,1.))\n",
    "        \n",
    "    if Channels.RFP in data:\n",
    "        rfp = normalize_images(data[Channels.RFP]['data'])\n",
    "        viewer.add_image(rfp, name='RFP', colormap='magenta', contrast_limits=(0.,1.))\n",
    "        viewer.layers['RFP'].blending = 'additive'\n",
    "        \n",
    "    if Channels.PHASE in data:\n",
    "        phase = normalize_images(data[Channels.PHASE]['data'])\n",
    "        viewer.add_image(phase, name='Phase', colormap='gray')\n",
    "    \n",
    "    if Channels.WEIGHTS in data:\n",
    "        weightmaps = data[Channels.WEIGHTS]['data']\n",
    "        viewer.add_image(weightmaps, name='weightmaps', colormap='plasma', visible=True)\n",
    "    \n",
    "    viewer.add_labels(seg, name='labels')\n",
    "    viewer.layers['labels'].opacity = 0.4\n",
    "    viewer.layers['weightmaps'].blending = 'additive'\n",
    "    \n",
    "\n",
    "    @viewer.bind_key('s')\n",
    "    def k_save_labels(viewer):\n",
    "        save_labels(viewer)\n",
    "        \n",
    "    @viewer.bind_key('w')\n",
    "    def k_calculate_weightmaps(viewer):\n",
    "        current_slice = viewer.layers[viewer.active_layer].coordinates[0]\n",
    "        calculate_weightmaps(viewer, current_slice=current_slice)\n",
    "        \n",
    "    @viewer.bind_key('<')\n",
    "    def k_shrink_label(viewer):\n",
    "        print('shrink label')\n",
    "        grow_shrink_label(viewer, grow=False)\n",
    "    \n",
    "    @viewer.bind_key('>')\n",
    "    def k_grow_label(viewer):\n",
    "        print('grow label')\n",
    "        grow_shrink_label(viewer, grow=True)\n",
    "        \n",
    "    @viewer.bind_key('o')\n",
    "    def k_output(viewer):\n",
    "        print('Output all with metadata')\n",
    "                \n",
    "        for i in range(viewer.layers['weightmaps'].data.shape[0]):\n",
    "            \n",
    "            if np.sum(viewer.layers['weightmaps'].data[i,...]) == 0:\n",
    "                print(f'Weighmap {i} is empty. Calculating...')\n",
    "                wmap = calculate_weightmaps(viewer, current_slice=i)\n",
    "                weight_folder = os.path.join(DATA_PATH, data[Channels.WEIGHTS]['sets'][i], 'weights')\n",
    "                weight_fn = data[Channels.WEIGHTS]['files'][i]\n",
    "                print(weight_folder, weight_fn)\n",
    "                make_folder(weight_folder)\n",
    "                io.imsave(os.path.join(weight_folder, weight_fn), wmap.astype(np.float32))\n",
    "            \n",
    "        # write out a JSON file with the data\n",
    "        jfn = os.path.join(DATA_PATH, 'training_metadata.json')\n",
    "        jdata = {}\n",
    "        for channel in data.keys():\n",
    "            jdata[channel.name.lower()] = data[channel]['path']\n",
    "            \n",
    "        with open(jfn, 'w') as json_file:\n",
    "            json.dump(jdata, json_file, indent=2, separators=(',', ': '))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert segmentation output labels to multichannel stacks\n",
    "\n",
    "# p = '/Users/arl/Dropbox/Data/TrainingData/set12'\n",
    "# files = [f for f in os.listdir(os.path.join(p,'labels')) if f.endswith('.tif')]\n",
    "# for f in files:\n",
    "#     mask = io.imread(os.path.join(p, 'labels', f))\n",
    "#     print(mask.shape)\n",
    "#     gfp = mask==1\n",
    "#     rfp = mask==2\n",
    "#     new_mask = np.stack([gfp, rfp], axis=0)\n",
    "#     io.imsave(os.path.join(p,f), new_mask.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:napari]",
   "language": "python",
   "name": "conda-env-napari-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
